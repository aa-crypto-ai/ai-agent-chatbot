version: '3'
services:
  ollama:
    image: ollama/ollama
    container_name: ollama
    build:
      context: .
      dockerfile: ollama.dockerfile
    volumes:
      - /root/.ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1 # alternatively, use `count: all`
              capabilities: [gpu]
    ports:
      - 11434:11434
    restart: always
  web:
    image: agent-chatbot
    build:
      context: .
    ports:
      - 7860:7860
    depends_on:
      - ollama
    command: "python app/server.py"
